{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import cifar10\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (50000, 32, 32, 3)\n",
      "Training labels shape:  (50000, 1)\n",
      "Test data shape:  (10000, 32, 32, 3)\n",
      "Test labels shape:  (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "# As a sanity check, we print out the size of the training and test data.\n",
    "print('Training data shape: ', X_train.shape)\n",
    "print('Training labels shape: ', y_train.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (49000, 32, 32, 3)\n",
      "Train labels shape:  (49000, 1)\n",
      "Validation data shape:  (1000, 32, 32, 3)\n",
      "Validation labels shape:  (1000, 1)\n",
      "Test data shape:  (1000, 32, 32, 3)\n",
      "Test labels shape:  (1000, 1)\n"
     ]
    }
   ],
   "source": [
    "#data split : train, val, test. In addition we'll create a small development\n",
    "num_training = 49000\n",
    "num_validation = 1000\n",
    "num_test = 1000\n",
    "num_dev = 500\n",
    "\n",
    "# The validation set will be num_validation points from the original\n",
    "# training set\n",
    "\n",
    "mask = range(num_training, num_training+num_validation)\n",
    "X_val = X_train[mask]\n",
    "y_val = y_train[mask]\n",
    "\n",
    "\n",
    "# The training set will be num_train points from the original\n",
    "# training set\n",
    "mask = range(num_training)\n",
    "X_train = X_train[mask]\n",
    "y_train = y_train[mask]\n",
    "\n",
    "\n",
    "# We will also make a development set, which is a small subset of\n",
    "# the training set.\n",
    "mask = np.random.choice(num_training, num_dev, replace=False)\n",
    "X_dev = X_train[mask]\n",
    "y_dev = y_train[mask]\n",
    "\n",
    "# We use the first num_test points of the original test set as our\n",
    "# test set.\n",
    "mask = range(num_test)\n",
    "X_test = X_test[mask]\n",
    "y_test = y_test[mask]\n",
    "\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (49000, 3072)\n",
      "Validation data shape:  (1000, 3072)\n",
      "Test data shape:  (1000, 3072)\n",
      "dev data shape:  (500, 3072)\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing: reshape the image data into rows\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
    "X_val = np.reshape(X_val, (X_val.shape[0], -1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
    "X_dev = np.reshape(X_dev, (X_dev.shape[0], -1))\n",
    "\n",
    "# As a sanity check, print out the shapes of the data\n",
    "print('Training data shape: ', X_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('dev data shape: ', X_dev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[130.64189796 135.98173469 132.47391837 130.05569388 135.34804082\n",
      " 131.75402041 130.96055102 136.14328571 132.47636735 131.48467347]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy86wFpkAAAACXBIWXMAAAsTAAALEwEAmpwYAAAL0klEQVR4nO3dX4ilhXnH8e+v/mlLFKLd6bKs2k2stHjRrDIslkhIkxqsNyqUohfBC2FDiaCQXkgKrYVemFKVXhTLWiVLsVpbFZcibawIEgjG0a7r6rbVyIa4rLsjVrQ3TdWnF+ddmJWZndk5/zZ5vh8Y5pz3vGffh5f9zpzzzuF9U1VI+vn3C/MeQNJsGLvUhLFLTRi71ISxS00Yu9TE2eM8Ocm1wF8BZwF/W1V3n2r9LVu21I4dO8bZpKRTOHz4MO+++25We2zTsSc5C/hr4BrgbeDFJPuq6vW1nrNjxw6WlpY2u0lJ61hcXFzzsXFexu8C3qyqt6rqp8CjwPVj/HuSpmic2LcDP1lx/+1hmaQz0NQP0CXZnWQpydLy8vK0NydpDePEfgS4eMX9i4ZlJ6mqPVW1WFWLCwsLY2xO0jjGif1F4LIkn0tyLnATsG8yY0matE0fja+qj5LcBvwroz+9PVRVr01sMkkTNdbf2avqaeDpCc0iaYr8BJ3UhLFLTRi71ISxS00Yu9SEsUtNGLvUhLFLTRi71ISxS00Yu9SEsUtNGLvUhLFLTRi71ISxS00Yu9SEsUtNGLvUhLFLTRi71ISxS00Yu9SEsUtNGLvUxFhXhElyGPgQ+Bj4qKrWvhK8pLkaK/bB71TVuxP4dyRNkS/jpSbGjb2A7yV5KcnuSQwkaTrGfRl/dVUdSfKrwDNJ/qOqnl+5wvBDYDfAJZdcMubmJG3WWL/Zq+rI8P048CSwa5V19lTVYlUtLiwsjLM5SWPYdOxJPpPk/BO3ga8BByc1mKTJGudl/FbgySQn/p2/r6p/mchUkiZu07FX1VvAFyY4i6Qp8k9vUhPGLjVh7FITxi41YexSE8YuNWHsUhPGLjVh7FITxi41YexSE8YuNWHsUhPGLjVh7FITxi41YexSE8YuNWHsUhPGLjVh7FITxi41YexSE8YuNWHsUhPrxp7koSTHkxxcsezCJM8keWP4fsF0x5Q0ro38Zv8ucO2nlt0JPFtVlwHPDvclncHWjX243vp7n1p8PbB3uL0XuGGyY0matM2+Z99aVUeH2+8wuqKrpDPY2AfoqqqAWuvxJLuTLCVZWl5eHndzkjZps7EfS7INYPh+fK0Vq2pPVS1W1eLCwsImNydpXJuNfR9wy3D7FuCpyYwjaVo28qe3R4AfAL+R5O0ktwJ3A9ckeQP43eG+pDPY2eutUFU3r/HQVyc8i6Qp8hN0UhPGLjVh7FITxi41YexSE8YuNWHsUhPGLjVh7FITxi41YexSE8YuNWHsUhPGLjVh7FITxi41YexSE8YuNWHsUhPGLjVh7FITxi41YexSE8YuNWHsUhMbufzTQ0mOJzm4YtldSY4k2T98XTfdMSWNayO/2b8LXLvK8vuqaufw9fRkx5I0aevGXlXPA+/NYBZJUzTOe/bbkhwYXuZfMLGJJE3FZmO/H7gU2AkcBe5Za8Uku5MsJVlaXl7e5OYkjWtTsVfVsar6uKo+AR4Adp1i3T1VtVhViwsLC5udU9KYNhV7km0r7t4IHFxrXUlnhrPXWyHJI8CXgS1J3gb+FPhykp1AAYeBb0xvREmTsG7sVXXzKosfnMIskqbIT9BJTRi71ISxS00Yu9SEsUtNGLvUhLFLTRi71ISxS00Yu9SEsUtNGLvUhLFLTRi71ISxS00Yu9SEsUtNGLvUhLFLTRi71ISxS00Yu9SEsUtNGLvUhLFLTawbe5KLkzyX5PUkryW5fVh+YZJnkrwxfPeyzdIZbCO/2T8CvlVVlwNXAd9McjlwJ/BsVV0GPDvcl3SGWjf2qjpaVS8Ptz8EDgHbgeuBvcNqe4EbpjSjpAk4rffsSXYAVwAvAFur6ujw0DvA1smOJmmSNhx7kvOAx4E7quqDlY9VVTG6fPNqz9udZCnJ0vLy8ljDStq8DcWe5BxGoT9cVU8Mi48l2TY8vg04vtpzq2pPVS1W1eLCwsIkZpa0CRs5Gh9G12M/VFX3rnhoH3DLcPsW4KnJjydpUs7ewDpfBL4OvJpk/7Ds28DdwGNJbgV+DPzBVCaUNBHrxl5V3weyxsNfnew4kqbFT9BJTRi71ISxS00Yu9SEsUtNGLvUhLFLTRi71ISxS00Yu9SEsUtNGLvUhLFLTRi71ISxS00Yu9SEsUtNGLvUhLFLTRi71ISxS00Yu9SEsUtNGLvUhLFLTWzkWm8XJ3kuyetJXkty+7D8riRHkuwfvq6b/riSNmsj13r7CPhWVb2c5HzgpSTPDI/dV1V/Ob3xJE3KRq71dhQ4Otz+MMkhYPu0B5M0Waf1nj3JDuAK4IVh0W1JDiR5KMkFkx5O0uRsOPYk5wGPA3dU1QfA/cClwE5Gv/nvWeN5u5MsJVlaXl4ef2JJm7Kh2JOcwyj0h6vqCYCqOlZVH1fVJ8ADwK7VnltVe6pqsaoWFxYWJjW3pNO0kaPxAR4EDlXVvSuWb1ux2o3AwcmPJ2lSNnI0/ovA14FXk+wfln0buDnJTqCAw8A3pjCfpAnZyNH47wNZ5aGnJz+OpGnxE3RSE8YuNWHsUhPGLjVh7FITxi41YexSE8YuNWHsUhPGLjVh7FITxi41YexSE8YuNWHsUhPGLjVh7FITxi41YexSE8YuNWHsUhPGLjVh7FITxi41YexSExu51tsvJflhkleSvJbkz4bln0vyQpI3k/xDknOnP66kzdrIb/b/Bb5SVV9gdHnma5NcBXwHuK+qfh34b+DWqU0paWzrxl4j/zPcPWf4KuArwD8Ny/cCN0xjQEmTsdHrs581XMH1OPAM8CPg/ar6aFjlbWD7VCaUNBEbir2qPq6qncBFwC7gNze6gSS7kywlWVpeXt7clJLGdlpH46vqfeA54LeBzyY5ccnni4AjazxnT1UtVtXiwsLCOLNKGsNGjsYvJPnscPuXgWuAQ4yi//1htVuAp6Y0o6QJOHv9VdgG7E1yFqMfDo9V1T8neR14NMmfA/8OPDjFOSWNad3Yq+oAcMUqy99i9P5d0s8AP0EnNWHsUhPGLjVh7FITxi41kaqa3caSZeDHw90twLsz2/janONkznGyn7U5fq2qVv302kxjP2nDyVJVLc5l487hHA3n8GW81ISxS03MM/Y9c9z2Ss5xMuc42c/NHHN7zy5ptnwZLzUxl9iTXJvkP4eTVd45jxmGOQ4neTXJ/iRLM9zuQ0mOJzm4YtmFSZ5J8sbw/YI5zXFXkiPDPtmf5LoZzHFxkueSvD6c1PT2YflM98kp5pjpPpnaSV6raqZfwFmMTmv1eeBc4BXg8lnPMcxyGNgyh+1+CbgSOLhi2V8Adw637wS+M6c57gL+aMb7Yxtw5XD7fOC/gMtnvU9OMcdM9wkQ4Lzh9jnAC8BVwGPATcPyvwH+8HT+3Xn8Zt8FvFlVb1XVT4FHgevnMMfcVNXzwHufWnw9oxN3woxO4LnGHDNXVUer6uXh9oeMTo6ynRnvk1PMMVM1MvGTvM4j9u3AT1bcn+fJKgv4XpKXkuye0wwnbK2qo8Ptd4Ctc5zltiQHhpf5U387sVKSHYzOn/ACc9wnn5oDZrxPpnGS1+4H6K6uqiuB3wO+meRL8x4IRj/ZGf0gmof7gUsZXSPgKHDPrDac5DzgceCOqvpg5WOz3CerzDHzfVJjnOR1LfOI/Qhw8Yr7a56sctqq6sjw/TjwJPM9886xJNsAhu/H5zFEVR0b/qN9AjzAjPZJknMYBfZwVT0xLJ75Plltjnntk2Hb73OaJ3ldyzxifxG4bDiyeC5wE7Bv1kMk+UyS80/cBr4GHDz1s6ZqH6MTd8IcT+B5Iq7BjcxgnyQJo3MYHqqqe1c8NNN9stYcs94nUzvJ66yOMH7qaON1jI50/gj44znN8HlGfwl4BXhtlnMAjzB6Ofh/jN573Qr8CvAs8Abwb8CFc5rj74BXgQOMYts2gzmuZvQS/QCwf/i6btb75BRzzHSfAL/F6CSuBxj9YPmTFf9nfwi8Cfwj8Iun8+/6CTqpie4H6KQ2jF1qwtilJoxdasLYpSaMXWrC2KUmjF1q4v8BqWX3Q3KPAa0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "UFuncTypeError",
     "evalue": "Cannot cast ufunc 'subtract' output from dtype('float64') to dtype('uint8') with casting rule 'same_kind'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-c2302621650f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# subtract the mean image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mmean_image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mX_val\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mmean_image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mmean_image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUFuncTypeError\u001b[0m: Cannot cast ufunc 'subtract' output from dtype('float64') to dtype('uint8') with casting rule 'same_kind'"
     ]
    }
   ],
   "source": [
    "# Preprocessing: subtract the mean image\n",
    "# compute the mean image\n",
    "mean_image = np.mean(X_train, axis=0).astype('uint8')\n",
    "print(mean_image[:10])\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.imshow(mean_image.reshape((32,32,3)).astype('uint8')) # visualize the mean image\n",
    "plt.show()\n",
    "\n",
    "# subtract the mean image\n",
    "X_train -= mean_image\n",
    "X_val -= mean_image\n",
    "X_test -= mean_image\n",
    "X_dev -= mean_image\n",
    "\n",
    "\n",
    "# append the bias dim of ones so that SVM only has to worry about optimizing a single weight matrix M\n",
    "\n",
    "X_train = np.hstack([X_train, np.ones((X_train.shape[0], 1))])\n",
    "X_val = np.hstack([X_val, np.ones((X_val.shape[0], 1))])\n",
    "X_test = np.hstack([X_test, np.ones((X_test.shape[0], 1))])\n",
    "X_dev = np.hstack([X_dev, np.ones((X_dev.shape[0], 1))])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
